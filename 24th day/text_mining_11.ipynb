{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 크롤링 수집된 문서\n",
    "# 2. 토크나이징 / 노말라이징\n",
    "# 3. BoW 문서가 벡터로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.corpus import kobill\n",
    "from konlpy.tag import Komoran\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1809890.txt',\n",
       " '1809891.txt',\n",
       " '1809892.txt',\n",
       " '1809893.txt',\n",
       " '1809894.txt',\n",
       " '1809895.txt',\n",
       " '1809896.txt',\n",
       " '1809897.txt',\n",
       " '1809898.txt',\n",
       " '1809899.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobill.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(s, n=2):\n",
    "    rst = list()\n",
    "    for i in range(len(s)-(n-1)):\n",
    "        rst.append(s[i:i+n])\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = list()\n",
    "\n",
    "for f in kobill.fileids():\n",
    "    d = kobill.open(f).read()\n",
    "    d = re.sub(r'^\\s|\\s$', '', re.sub(r'\\s+', ' ', d))\n",
    "    \n",
    "    V.extend(word_tokenize(d))\n",
    "    V.extend(ngram(d, 2))\n",
    "    V.extend(ngram(d, 3))\n",
    "\n",
    "    V.extend(ma.morphs(d))\n",
    "    V.extend(['/'.join(t) for t in ma.pos(d)])  # 형태소\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134694, 15274)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(V), len(set(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = Counter(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zif's rule\n",
    "# 상위에 있는애들 하위에 있는 애들 자르는데\n",
    "# moder ie에서는 굳이 저렇게 안하므로\n",
    "CV = list(set(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = kobill.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM = [[0 for j in range(len(CV))] for i in range(len(D))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in D:\n",
    "    i = D.index(f)\n",
    "    d = kobill.open(f).read()\n",
    "    d = re.sub(r'^\\s|\\s$', '', re.sub(r'\\s+', ' ', d))\n",
    "\n",
    "    for t in word_tokenize(d)+ngram(d,3)+ngram(d,2)+ma.morphs(d)+['/'.join(t) for t in ma.pos(d)]:\n",
    "        # term을 찾아야함\n",
    "        # cv에서 index 찾기\n",
    "        j = CV.index(t)\n",
    "        DTM[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 생성\n",
    "Q  = '대통령 국민 국회'\n",
    "rst = list()\n",
    "# Query 까기\n",
    "for q in Q.split(): # Query 개수만큼\n",
    "    k = CV.index(q)\n",
    "    rst.append(list())  # Qeury 개수만큼 존재해야하므로 세팅\n",
    "\n",
    "    # bottleneck\n",
    "    # Query 개수만큼마다 늘어나야하므로\n",
    "    # 따라서 바꿈 어떻게? TDM의 형태로\n",
    "\n",
    "    for i,d in enumerate(DTM):   # Document 개수만큼 돌아야함\n",
    "        for j,t in enumerate(d): # V만큼 돌아야함\n",
    "            if k == j and t == 1:   # 이때만 rst에 append\n",
    "                rst[-1].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 3, 4, 6, 9], [4, 6, 7], [0, 1, 2, 3, 6, 7, 8]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "candi = set(rst[0])\n",
    "for r in rst[1:]:\n",
    "    candi = candi.intersection(set(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([6], [[0, 1, 3, 4, 6, 9], [4, 6, 7], [0, 1, 2, 3, 6, 7, 8]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(candi), rst\n",
    "# 0 번째 문서에 3개의 단어가 다 들어가 있다\n",
    "# 이게 검색하는 원리\n",
    "# 가장 빠름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDM으로 바꿨을 때\n",
    "TDM = [[0 for j in range(len(D))] for i in range(len(CV))]  # transpose한 것과 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in D:\n",
    "    i = D.index(f)\n",
    "\n",
    "    d = kobill.open(f).read()\n",
    "    d = re.sub(r'^\\s|\\s$', '', re.sub(r'\\s+', ' ', d))\n",
    "\n",
    "    for t in word_tokenize(d)+ngram(d,2)+ngram(d,3)+ma.morphs(d) + ['/'.join(t) for t in ma.pos(d)]:\n",
    "        j = CV.index(t)\n",
    "        TDM[j][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = '대통령 국민 국회'\n",
    "\n",
    "rst = list()\n",
    "\n",
    "for q in Q.split():\n",
    "    k = CV.index(q)\n",
    "    rst.append([i for i, v in enumerate(TDM[k]) if v == 1])\n",
    "# bottleneck 사라짐\n",
    "# inverted index의 구조\n",
    "\n",
    "# TDM이면서 Inverted Index의 구조를 띈 형태\n",
    "# 이것을 linked list로 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary = dict()\n",
    "Posting = list()\n",
    "\n",
    "for f in D:\n",
    "    i = D.index(f)\n",
    "\n",
    "    d = kobill.open(f).read()\n",
    "    d = re.sub(r'^\\s|\\s$', '', re.sub(r'\\s+', ' ', d))\n",
    "\n",
    "    for t in word_tokenize(d)+ngram(d,2)+ngram(d,3)+ma.morphs(d) + ['/'.join(t) for t in ma.pos(d)]:\n",
    "        j = CV.index(t)\n",
    "        if t not in Dictionary:\n",
    "            Dictionary[t] = len(Posting)\n",
    "            Posting.append((i, -1))\n",
    "        else:\n",
    "            pos = Dictionary[t]\n",
    "            Dictionary[t] = len(Posting)\n",
    "            Posting.append((i, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst = list()\n",
    "pos = Dictionary['국민']\n",
    "while pos != -1:\n",
    "    i, pos = Posting[pos]\n",
    "    rst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import pack, unpack\n",
    "# file로 바꾸기 위해서 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack('i', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m local\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m Dictionary:\n\u001b[1;32m---> 13\u001b[0m         \u001b[43mDictionary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m     14\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(pack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miii\u001b[39m\u001b[38;5;124m'\u001b[39m, i, v, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "fp = open('posting.dat', 'wb')\n",
    "    \n",
    "for f in D:\n",
    "    i = D.index(f)\n",
    "\n",
    "    d = kobill.open(f).read()\n",
    "    d = re.sub(r'^\\s|\\s$', '', re.sub(r'\\s+', ' ', d))\n",
    "\n",
    "    local = Counter(word_tokenize(d)+ngram(d,2)+ngram(d,3)+ma.morphs(d) + ['/'.join(t) for t in ma.pos(d)])\n",
    "    # 문서 1개에 대해서, 단어:빈도, 단어:빈도 ...\n",
    "    for k, v in local.items():\n",
    "        if k not in Dictionary:\n",
    "            Dictionary[k] = fp.tell()\n",
    "            fp.write(pack('iii', i, v, -1))\n",
    "        else:\n",
    "            pos = Dictionary[k]\n",
    "            Dictionary[k] = fp.tell()        \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mDictionary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m국민\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m fp\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposting.dat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pos \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "pos = Dictionary['국민']\n",
    "\n",
    "fp.open('posting.dat', 'rb')\n",
    "while pos != -1:\n",
    "    fp.seek(pos)\n",
    "    i, freq,npos = unpack('iii', fp.read(12))\n",
    "    pos = npos\n",
    "    print(i, freq)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoreaUniv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
