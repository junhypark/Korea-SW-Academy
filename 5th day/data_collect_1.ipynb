{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression\n",
    "# . => 아무글자 한개\n",
    "# 캐릭터 => 캐릭터 그대로 일치\n",
    "# ? => 있거나 없거나\n",
    "# * => 0개 이상\n",
    "# + => 1개이상\n",
    "# {n,m} => n개보다 많이 m개보다 적게\n",
    "# {0,} = * / {1,} = 1개보다 많이\n",
    "# ^ => ~로 시작하는\n",
    "# $ => ~로 끝나는\n",
    "# [-] => 범위\n",
    "# [^] => not의 의미\n",
    "# [작은코드-큰코드] => a-z, ㄱ-ㅎ 이런 식으로\n",
    "# \\d => s숫자\n",
    "# \\w => 문자\n",
    "# \\b => 단어 경계\n",
    "# \\s => 공백문자\n",
    "# 대문자 시에는 반대의미\n",
    "# () => 그룹 + 캡쳐링\n",
    "# (?:) => 그룹 + 캡쳐링X\n",
    "# greedy vs lazy => +? 를 넣으면 바뀜\n",
    "# 나중에    처음에 일치 => HTML parsing 시에 쓰임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '''\n",
    "홍길동 980311-1231231\n",
    "아무나 001231-2123121\n",
    "누구   011111-3445211\n",
    "'''\n",
    "\n",
    "import re\n",
    "\n",
    "re.sub(r'(\\d{6})-\\d{7}', r'\\g<1>-******', data)\n",
    "re.sub(r'(\\w+)\\s+((\\d{6})-\\d{7})',r'\\g<3>-******* \\g<1>', data) # => group에 대해서 \\g<3>은 그룹 안에서 그룹으로 나눈 얘를 의미함\n",
    "# 또한, (\\w+) 얼마나 많은 word가 나오든지 그리고 \\s 스페이스가 얼마나 많아도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data='''\n",
    "www.naver.com\n",
    "naver.com\n",
    "www.naver.com/index.html\n",
    "http://www.naver.com\n",
    "https://www.naver.com/\n",
    "https://mail.naver.com/latest/list?a=b\n",
    "https://mail.naver.com/latest#top\n",
    "ftp://ftp.daum.net\n",
    "ftp://ftp.korea.ac.kr\n",
    "'''\n",
    "\n",
    "# scheme://service.(host)netloc/path/file?params... #fragment\n",
    "re.findall(r'(?:([a-z]+):\\/\\/)?[.]?[a-z0-9\\-]{3,}(?:[.]?[a-z0-9\\-]{2,})+\\/?([a-z]{3,}\\/)*?', data)\n",
    "# 캡쳐링을 빼기 전에는 .com, .html 등등 지멋대로 나옴\n",
    "# 캡쳐링을 뺀 후에는 www.naver.com 등 원하는 값들이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '''\n",
    "<article>\n",
    "    <h1>제목</h1>\n",
    "    <p>내용</p>\n",
    "    <h2>제목2</h2>\n",
    "    <h3>제목3</h3>\n",
    "</article>\n",
    "'''\n",
    "\n",
    "re.findall(r'<h[1-6]>(.+)</h[1-6]>', data)\n",
    "# 여기서 lazy로 바꾸면\n",
    "# re.findall(r'<h[1-6]>(.+?)</h[1-6]>', data)\n",
    "# greedy 한 경우에는 태그가 nested 되었을 떄 예를 들어, <h1>제목<h2>제목2</h2></h1> 이런식일 때 원하는 내용만 추출할 수 없음 따라서 lazy로 바꿔줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 27]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "bonus = {'S': 1, 'D': 2, 'T': 3}\n",
    "option = {'*': 2, '#': -1}\n",
    "# Dictionary로 switch case 문을 대신해서 사용 가능함\n",
    "\n",
    "def solution(dartResult):\n",
    "    answer = 0\n",
    "    tm = re.findall(r'(\\d)([|S|D|T])([*|#]?)', dartResult)\n",
    "    li = []\n",
    "    for i in range(len(tm)):\n",
    "        str = int(tm[i][0])**int(bonus[tm[i][1]])*(int(option[tm[i][2]]) if tm[i][2] != '' else 1)\n",
    "        li.append(str)\n",
    "        \n",
    "        if tm[i][2] == '*' and len(li) > 1:\n",
    "            li[i-1] *= 2\n",
    "        \n",
    "    return li\n",
    "\n",
    "data= '1S2D*3T'\n",
    "\n",
    "solution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL vs URI => url은 file path가 들어가 있지만 uri는 parameter들이 포함된 path가 나옴\n",
    "# HTTP는 HTML로 소통을 한다 (주고 받을떄 왜냐하면 hypertext로 소통을 하는데 HTML이 이 hypertext이기 때문이다)\n",
    "# HTTP는 요청과 응답이 쌍으로 되어 있고, HTML은 주소를 분석하는 것이 제일 중요하다\n",
    "# REST 방식으로 돌아가는 API를 RESTful API를 사용\n",
    "# REST 방식으로 만들어서 돌아갈 수 있도록 하는 API\n",
    "# REST 방식은 path는 같지만 동작을 다르게 하는 방식을 RESTful API라고 한다\n",
    "\n",
    "# Crawling = 링크를 따라다님, 링크 수집\n",
    "# Scraping = 링크 내에서 원하는 컨텐츠만 가져오는 것을 뜻함\n",
    "\n",
    "# 법적인 이슈: 데이터를 웹에서 다룰 때, 검색 엔진 / 가격비교 -> 합법 / 가입을 하든 안하든 정보를 보여주고 있기 때문이다\n",
    "# 불법인 요소들\n",
    "# 1. bot을 사용하면 1초에 여러번의 req를 보내므로 의도치않게 DDoS 공격을 하는 것과 비슷하게 된다 / 운영을 방해하므로 -> 5초 혹은 10초 간격으로 하면 된다\n",
    "# 2. 이용 방침, 정보 처리 요건이 이미 있음 -> 이용방침 확인 후 걸리지 않는 선에서\n",
    "# 3. DB는 건들면 안됨 -> 개인을 식별할 수 있는 정보는 가져올 생각을 안하는 것이 좋다 -> 정규식에서 걸러줘야함\n",
    "# 4. 지적재산권 또한 같은 맥락에서 건들면 안됨\n",
    "\n",
    "# 크롤링은 누구 데이터를 어떤 목적으로 쓰는지가 더 중요함\n",
    "# 이용방침 준수\n",
    "\n",
    "# 1. robots.txt 확인\n",
    "# 2. traffic 때문에 부담되지 않게\n",
    "# 3. 이용약관 꼭 확인\n",
    "# 4. 민감한 정보 수집 주의\n",
    "# 5. 지적 재산권 침해 여부 주의\n",
    "# 개인이 공부 목적으로만 사용하고 바로 폐기한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collect\n",
    "\n",
    "#### URL vs URI\n",
    "\n",
    "URL contains file path, URI has path and parameters\n",
    "\n",
    "#### HTTP\n",
    "\n",
    "HTTP communicate using HTML since communicate with hypertext\n",
    "\n",
    "#### RESTful API\n",
    "\n",
    "RESTful API is an API has REST techniques\n",
    "\n",
    "REST - same path but perform differently such as POST, PUT, GET, ...\n",
    "\n",
    "#### Crawling vs Scraping\n",
    "\n",
    "Crawling - collecting links\n",
    "\n",
    "Scrapping - collecting contents inside of links\n",
    "\n",
    "#### Ethics\n",
    "\n",
    "Illegal\n",
    "\n",
    "1. Do not send frequent request like robot - it performs similar like DDoS\n",
    "2. Do not violate usage policy and personal data policy\n",
    "3. Do not access to DB\n",
    "4. Do not use intellectual property\n",
    "\n",
    "What we have to do?\n",
    "\n",
    "1. Check robots.txt - Do what robots.txt allows\n",
    "2. Do not send too much request - do not disturb traffic\n",
    "3. Check usage policy\n",
    "4. Do not collect personal information\n",
    "5. Do not violate intellectual property"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoreaUniv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
