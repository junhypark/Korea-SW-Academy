{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representation learning\n",
    "# CNN\n",
    "\n",
    "# deep learning book\n",
    "# 거의 바이블인데 기본서다\n",
    "\n",
    "# representation learning\n",
    "# 데이터를 다른 형태로 변환 (목적에 맞는 데이터 형태)\n",
    "# 어떻게 표현하는가에 따라서 머신러닝 성능이 달라지기 때문이다\n",
    "# 하지만, dll은 표현하는 것을 학습을 통해서 하는 것\n",
    "# 따라서, 표현 방법에 따라서 성능이 달라졌다면\n",
    "# 이제는 데이터를 기준으로 성능이 달라지기 않는다\n",
    "# 그래서 성능이 좋을 수 밖에 없다\n",
    "\n",
    "# 따라서, dll의 핵심은 representation\n",
    "# 레이어를 통과하면서 데이터 형태가 바뀌는데\n",
    "# 마지막에 우리가 원하는 데이터 형태로 나온다\n",
    "# representation으로 linear한 형태로 바뀌게 된다\n",
    "# 이때, 문제가 존재\n",
    "# 이미지의 경우,\n",
    "# 1. 차원의 저주 문제 -> 데이터가 많으면 해결가능함\n",
    "# 2. 공간적인 의미가 사라짐 (flatten했을 때) 따라서 한계가 존재함 (로컬 정보를 잃어버린다)\n",
    "# 그래서 입력을 2차 이상으로 받는 것으로 해결\n",
    "\n",
    "# 뉴럴 네트워크의 문제점\n",
    "# 1. 고양이의 위치가 바뀔 수록 고양이 인식을 못함\n",
    "# 2. 사람은 고양이의 눈, 코, 입 등의 특성으로 인식하는데 이를 수행하지 못함\n",
    "\n",
    "# 특성이 있는지 없는지의 문제로 바꾼다 (신호의)\n",
    "# 이미지는 독립적이지 않으므로 머신러닝에서 문제가 생길 수 있다\n",
    "# ex. welcome 일때 w,e,l,..이 나왔는데 순서대로 나오지 않을 수 있으므로 존재 유무 차이로 하면 문제가 존재했다\n",
    "# 그래서 welcome의 위치를 보고 위치 확인함\n",
    "# 하지만 feature 존재로 확인할 경우에서 문제가 존재함\n",
    "# 이를 해결하기 위해서 window size의 다양성으로 해결할 수 있다\n",
    "# fc에서는 위치와 크기에 따라서 task가 해결이 안되는문제\n",
    "# 이를 해결하려고 window의 위치와 크기의 다양성으로 독립성 가정 문제가 해결됨\n",
    "\n",
    "# equivalance = 이동을 해도 특성이 사라지지 않으므로 특성이 같으면 equivalance라고 한다 (즉, 이동 말고 바뀐게 없을 때)\n",
    "# invariance = 이동해도 안변하는 것을 특성이 변하지 않는 것\n",
    "# convolution = translation equivalance의 종류 (이동을 해도 똑같은 것을 인식하는 애)\n",
    "# 따라서, 데이터의 양이 확 줄어들 수 있다 (성능을 높이는데 사용)\n",
    "\n",
    "# 이미지를 쪼갬 (window를 이동시키는 것이 아님)\n",
    "# 이 쪼갠 이미지를 보면서 결과값이 있는지 없는지 보는 것\n",
    "# 이것이 convolution - 새로운 데이터 형식의 연산\n",
    "\n",
    "# convolution - 면적의 넓이를 함수로 나타냄 (불연속을때는 내적처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([-2,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   1,   0,  -1,  -8, -10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.correlate(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation 연산\n",
    "# a를 padding함\n",
    "# 두 패턴이 비슷하면 비슷할수록 값이 크다\n",
    "# pattern의 존재 유무를 알 수 있다\n",
    "# 하지만 교환법칙이 성립되지 않아서 convolution이 나옴\n",
    "# correlate(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conbolution = flip + correlation\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2,  0,  1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0, -2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   1,   0,  -1,  -8, -10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.correlate(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  4, -7, -6, -5, -4, -2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.correlate(np.flip(b), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -4, -5, -6, -7,  4,  5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.correlate(a, np.flip(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -4, -5, -6, -7,  4,  5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.correlate(b, np.flip(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution은 교환법칙이 적용되므로 correlation 연산을 한다\n",
    "# 그래서 왜? convolution ? 수학적으로 증빙하기 위해서\n",
    "# 특성의 있고 없고의 여부를 따질 때, 교한 법칙 시에 값이 동일하므로 존재 여부 따지기가 좋다\n",
    "# convolution의 다른 특성: 내적 연산\n",
    "# 이미지 처리에서는 filter로 쓰인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재정리\n",
    "# ML에서의 이미지 처리는\n",
    "# 1. 1차 형태의 데이터로 바꿔야한다 - 문제: 차원의 저주, 로컬 정보 손실\n",
    "# Neural Network의 문제점 - FC이므로 크기와 위치 회전 등 다르면 다 다르다고 인식을 한다\n",
    "# 따라서, 해결하기 위해서\n",
    "# 1. 2,3 차 형태로 input data를 구성한다 (1차로 변환시킬 때 문제)\n",
    "# 2. 위의 문제점을 특성이 있는지 없는지의 형태로 변환 - 정보의 손실이 적고, 독립성 과정도 가능하다, 로컬 정보 활용 가능하다\n",
    "\n",
    "# ---- correlation ---- > 로컬 정보 활용 - 로컬 정보 손실 해결\n",
    "# 1차로 변환 시, 문제 소지 감소, 독립성 가정 확보\n",
    "# 하지만 correlation은 교환법칙이 성립을 못하므로 증명이 힘듦\n",
    "# 그래서 convolution = correlation + flip\n",
    "# 이를 통해 위치의 문제가 상관이 없어진다\n",
    "# 이러면 neural network의 연산 특징과 유사하다\n",
    "# 이때, flip은 교환법칙 성립을 위해서...\n",
    "# 하지만 하나의 특징으로 모든 것을 해결 못하는 문제가 생김\n",
    "\n",
    "# 따라서 이것을 여러개 사용하면 여러 특징을 볼 수 있다\n",
    "\n",
    "# 이미지 > 이미지 (image processing) : filter (convolution을 filter로 활용함)\n",
    "# cnn explainer\n",
    "\n",
    "# CNN (input = 2, 3 dimension why? 정보 손실이 작아지므로)\n",
    "# convolution2D layer\n",
    "# flatten layer\n",
    "# FC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoreaUniv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
