{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning, ReLU, Sigmoid, tanh etc\n",
    "# audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voice, voice 가 아닌 그 외(sound)\n",
    "# sound\n",
    "# 1. 악기 소리\n",
    "# 2. 악기가 아닌 noise\n",
    "# \n",
    "# voice\n",
    "# 음성인식 (voice -> text)\n",
    "# 음성 합성 (text -> voice)\n",
    "# 화자 인식 (voice -> who?) { 화자 분리 (누가 무슨 말을 했는지), 화자 인식 (A가 누구인지, B가 누구인지) }\n",
    "# voice conversion (voice 변환) = 목소리 위조\n",
    "# (voice = speaker에 대한 info + lang에 대한 info + style(억양, etc.) / speaker에 대한 info를 바꾸는 것)\n",
    "# song을 conversion (1번 가수를 2번 가수로 바꾸는 작업 / AI cover)\n",
    "# 박명수가 부른 노래에서 vocal만 분리 하지만 어렵다 왜?\n",
    "# 분리에서 부른 사람의 파트와 반주는 분리가 어려운 기술이다\n",
    "# 하지만 메타에서 존재하는 transformer를 사용하면 어느정도 필터링이 가능하다\n",
    "\n",
    "# voice와 sound가 같이 있는 경우\n",
    "# 음악, 노래\n",
    "\n",
    "# 음악, 노래를 만들어주는 ai 또한 이미 존재\n",
    "# 예를 들어, jazz를 넣으면 jazz에 맞는 음악을 만들어줌\n",
    "\n",
    "# 음성에다가 감정을 넣는 것 또한 가능하다 (억양 혹은 style을 달리하면 감정이 내포되기 때문)\n",
    "# 오디오 핑거프린팅 기술 - 음성에서 특정 습관을 추출하여 사용자 인식\n",
    "# 음성 검색 - 음악 검색이 존재함\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoreaUniv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
